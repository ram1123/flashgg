* HHWWgg Development 

Contacts: 
- Abraham Tishelman-Charny - abraham.tishelman.charny@cern.ch 
- Badder Marzocchi - badder.marzocchi@cern.ch
- Toyoko Orimoto - Toyoko.Orimoto@cern.ch 

Presentations: 
- [[https://indico.cern.ch/event/904968/contributions/3866826/attachments/2041516/3419252/19_May_2020_HH_WWgg_NonResStatus.pdf][19 May 2020 Non-Res Status]]
- [[https://indico.cern.ch/event/847923/contributions/3632148/attachments/1942588/3221820/HH_WWgg_Analysis_Update_11_November_2019_2.pdf][11 November 2019 Update]]
- [[https://indico.cern.ch/event/847927/contributions/3606888/attachments/1930081/3196452/HH_WWgg_Analysis_Status_21_October_2019.pdf][21 October 2019 Status]]

Repositories:
- [[https://github.com/atishelmanch/flashggFinalFit/tree/HHWWgg_Dev_runII_102x][HHWWgg Flashgg Final Fit]]
- [[https://github.com/atishelmanch/flashgg/tree/HHWWgg_Crab][HHWWgg MicroAOD Production]]
- [[https://github.com/NEUAnalyses/HHWWgg_Tools/tree/master][HHWWgg Analysis Tools]]

These instructions describe how to run flashgg modules specific to the HH->WWgg analysis. The current plugin designed to work with workspaceStd is the HHWWgg Tagger. 

** Cloning the HHWWgg_dev Repository 

The HHWWgg development branch is obtained in a similar fasion to the dev_legacy_runII branch: 

   #+BEGIN_EXAMPLE
   export SCRAM_ARCH=slc7_amd64_gcc700
   cmsrel CMSSW_10_5_0 
   cd CMSSW_10_5_0/src
   cmsenv
   git cms-init
   cd $CMSSW_BASE/src 
   git clone -b HHWWgg_dev https://github.com/atishelmanch/flashgg 
   source flashgg/setup_flashgg.sh
   #+END_EXAMPLE

   If everything now looks reasonable, you can build:
   #+BEGIN_EXAMPLE
   cd $CMSSW_BASE/src
   scram b -j 4
   #+END_EXAMPLE

** Setting up a voms Proxy 

To access grid files to run the tagger on, you must run the following commands:

    #+BEGIN_EXAMPLE
    cmsenv
    voms-proxy-init --voms cms --valid 168:00
    #+END_EXAMPLE

after the voms command, you should receive an output similar to:

    #+BEGIN_EXAMPLE
    Created proxy in /tmp/x509up_u95168
    #+END_EXAMPLE

to set this proxy to your X509_USER_PROXY environment variable for the example above, simply use the command:

    #+BEGIN_EXAMPLE
    . proxy.sh x509up_u95168
    #+END_EXAMPLE

where x590up_u95168 would be replaced by whatever your proxy name is. 

** HHWWgg Tagger

The HHWWgg tagger is developed to tag events as coming from the HH->WWgg process, and is compatible with workspaceStd in order to include the standard systematics workflow, 
and if desired to include tagging of other flashgg tags on the same events. 

*** Running Locally 

The HHWWgg Tagger can be run locally on signal with:

    #+BEGIN_EXAMPLE
    cmsRun Systematics/test/workspaceStd.py metaConditions=MetaData/data/MetaConditions/Era2017_RR-31Mar2018_v1.json campaign=HHWWgg_v2-3 dataset=ggF_X250_WWgg_qqlnugg doHHWWggTag=1 HHWWggTagsOnly=1 maxEvents=500 doSystematics=0 dumpWorkspace=0 dumpTrees=1 useAAA=1
    #+END_EXAMPLE

and on data:
    #+BEGIN_EXAMPLE
    cmsRun Systematics/test/workspaceStd.py metaConditions=MetaData/data/MetaConditions/Era2017_RR-31Mar2018_v1.json campaign=Era2017_RR-31Mar2018_v2 dataset=/DoubleEG/spigazzi-Era2017_RR-31Mar2018_v2-legacyRun2FullV1-v0-Run2017B-31Mar2018-v1-d9c0c6cde5cc4a64343ae06f842e5085/USER doHHWWggTag=1 HHWWggTagsOnly=1 maxEvents=500 doSystematics=0 dumpWorkspace=0 dumpTrees=1 useAAA=1 processId=Data processType=Data
    #+END_EXAMPLE

All flags are either defined in MetaData/python/JobConfig.py, or workspaceStd. 

An explanation of the flags in this example:
- metaConditions: A json file of tags and conditions defined for each year. In this example, 2017 conditions is specified, used to run with correct conditions on 2017 Data and MC.
- campaign: The flashgg campaign where the files you want to run on are defined.
- dataset: The dataset within the specified campaign where the files you want to run on are defined. 
- doHHWWggTag: Setting this flag to 1 tells the workspaceStd flow to evaluate each event with the HHWWgg Tagger.
- HHWWggTagsOnly: This flag removes all taggers other than the HHWWgg Tagger, mainly all of the Higgs->gg taggers. 
- doSystematics: In this example set to 0. If set to 1, the workspaceStd systematics flow is included where systematic labels are defined in workspaceStd. For each systematic, the tagger is rerun on the microAOD where the systematic quantity is either varied up or down one sigma. If you run with this flag on, there should be a tree (if running with dumpTrees) or a RooDataHist (if running with dumpWorkspace) for each systematic variation.
- maxEvents: Max events to run over in the specified dataset. Set to -1 to run on all events. 
- dumpWorkspace: Save RooWorkspace in output file. Useful for input into fggfinalfit. 
- dumpTrees: Save tree(s) in output file. Useful for running ntuple analysis afterwards.
- useAAA: Use prefix: "root://cms-xrd-global.cern.ch/" when looking for files.
- processId / processType: Set to "Data" when running on data. 

With the options specified in the example, if this works properly, you should get an output file named: output_numEvent500.root containing a tree for each HHWWggTag. 

The customization for the HHWWggTag class is defined in a few places, starting with Systematics/python/HHWWggCustomize.py. In this python module you can specify variables to save, and the number of categories to save HHWWggTag objects in. The selections are located in 
Taggers/plugins/HHWWggTagProducer.cc. For the moment, a tag object "tag_obj" is created if an event has a diphoton, exactly one good lepton, corresponding
to the leptonically decaying W boson, and at least two 'good' jets, corresponding to the hadronically decaying W boson. For these objects, 'good' is defined by the selections specified in 
Taggers/python/flashggHHWWggTag_cfi.py. This tag object can be created and placed into one of three categories:

- HHWWggTag_0: Semileptonic electron final state (qqlnugg with l = electron)
- HHWWggTag_1: Semileptonic muon final state (qqlnugg with l = muon)
- HHWWggTag_2: Untagged (if doHHWWggTagCutFlow=1) 

Note that the untagged category is only filled if you are running with the flag doHHWWggTagCutFlow=1. To add another category, the number of categories
specified in Systematics/python/HHWWggCustomize.py should be changed like so: self.tagList = [ ["HHWWggTag",3] ] -> self.tagList = [ ["HHWWggTag",4] ]. Then, when saving a tag object
of the new category, you would do so in Taggers/plugins/HHWWggTagProducer.cc with tag_obj.setCategoryNumber( 3 ) rather than tag_obj.setCategoryNumber( catNum ) where catNum = 0, 1, or 2. 

*** Running on Condor 

When running over entire datasets, it's useful to submit confor jobs instead of running locally. This is done with the script HHWWgg_Run_Jobs.sh. 

*Note* : You must first follow the proxy steps above in order to have access to DAS datasets.
*Note* : There are two user specific parameters in the script: fggDirec and ntupleDirec, which are be default set to:

    #+BEGIN_EXAMPLE
    fggDirec="/afs/cern.ch/work/a/atishelm/21JuneFlashgg/CMSSW_10_5_0/src/flashgg/" # flashgg directory 
    ntupleDirec="/eos/user/a/atishelm/ntuples/HHWWgg/" # condor output directory 
    #+END_EXAMPLE

- fggDirec: Your current working directory where you have flashgg cloned. 
- ntupleDirec: The directory where you want your output files to go. Note that this is the directory where a directory will be created for each batch of jobs, so you don't need to change this for every submission. 

There are two submission types currently in HHWWgg_Run_Jobs.sh: 
- Trees with many final state variables 
- Workspaces with minimal variables 

The many final state variables job is useful for studying the kinematics of all final state objects, including leptons and jets before and after selections, as 
well as the two photons associated with the diphoton candidate. As an example, to run over 1000 events of signal and save trees with final state variables, one should run:

    #+BEGIN_EXAMPLE
    . HHWWgg_Run_Jobs.sh --labelName HHWWgg_v2-6_Trees_Test --nEvents 1000 --json Taggers/test/HHWWgg_v2-6/HHWWgg_v2-6.json --condorQueue longlunch -g -c -v -t
    #+END_EXAMPLE

An explanation of the flags:
- labelName: The name used for the output folder placed in ntupleDirec
- nEvents: The max events to run on. To run on all events, specify the flag like so: "--nEvents all"
- json: The json file to use for fggrunjobs submission. This should contain the datasets to run on, and specify the campaign, and PU target for MC jobs
- condorQueue: The [[https://twiki.cern.ch/twiki/bin/view/ABPComputing/LxbatchHTCondor#Queue_Flavours][condor flavour]] for the condor jobs. Note that this needs to be carefully selected, otherwise jobs may timeout and no output will be produced.
- g: Use workspaceStd as the cms configuration file 
- c: Run HHWWgg cut flow. This means all events that pass preselection will be saved in output nTuples. 
- v: Save HHWWgg final state variables. Currently set up to be MANY variables (this should be noted. It may take more computing time than normal)
- t: Save trees in output nTuples. Useful for python modules / c++ macros designed for nTuple analysis with TTrees / TBranches. 

In this example the HHWWgg_v2-6 json is specified. This is a campaign with three signal mass points: 260, 600, 1000 GeV Radion decaying semileptonically with all lepton decays, including taus.
Any json file can be specified as long as it is formatted properly. You should be able to find some examples under Taggers/test/*HHWWgg*. These input json files 
can also be created from text files of dataset names with SampleTools.py. 

*Note* : In order for flashgg campaigns to be defined and therefore accessed via the fggrunjobs json specified with the --json flag, they must be created with 
fggManageSamples.py. You can find instructions for performing this [[https://twiki.cern.ch/twiki/bin/viewauth/CMS/AbrahamTishelmanCharnyHomepage#Adding_MicroAOD_s_to_a_flashgg_C][here]] and [[https://github.com/cms-analysis/flashgg/tree/dev_legacy_runII/MetaData#importing-datasets-from-dbs][here]].  

If your campaign exists in MetaData/data/, specifying the campaign and datasets in the json should be defined properly for fggrunjobs. Note that HHWWgg_v2-6 should be defined for this state of the cloned repository.

To produce workspaces with minial variables to be used by fggfinalfit, you can for example run:

    #+BEGIN_EXAMPLE
    . HHWWgg_Run_Jobs.sh --labelName HHWWgg_v2-6_Workspaces_X600_Test --nEvents all --json Taggers/test/HHWWgg_v2-6/HHWWgg_v2-6_X600.json --condorQueue microcentury -g -s -w 
    #+END_EXAMPLE

Explaining the new flags:
- s: Run flashgg systematics workflow. Required to obtain final results in fggfinalfit with systematic uncertainty.
- w: Save workspaces in output. Used by fggfinalfit. 

If this works properly, the output will be files (to be hadded) containing a RooWorkspace with the variables required for fggfinalfit, namely CMS_hgg_mass and dZ (for signal). 

** nTuple Processing

After your condor jobs are complete, you should have a number of output files for each signal point or data taking era. This section will describe how to hadd the files properly.

*** Trees

If you ran with trees, these are hadded in the usual way with the hadd command (Documentation Needed).

*** Workspaces

If you ran with workspaces, you need to hadd the workspaces in order to obtain a root file with a single combined root workspace for each signal point to work with
fggfinalfit. This can be done with the script HHWWgg_Process_Files.sh (Documentation Needed). 