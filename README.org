* HHWWgg

Contact: Abe Tishelman-Charny, abraham.tishelman.charny@cern.ch 

See: https://indico.cern.ch/event/847923/#12-update-on-the-hh-wwgg-analy

These instructions describe how to run modules specific to the HH->WWgg analysis. The current plugin designed to work with workspaceStd
(as of 6 December 2019) is the HHWWgg tagger. One can also run a non-standard flashgg sequence, specific to HHWWgg, with the HHWWgg candidate dumper. 

*** Get HHWWgg branch of flashgg 

The HHWWgg development branch is obtained in a similar fasion to obtaining the dev_legacy_runII branch of flashgg:

   #+BEGIN_EXAMPLE
   cmsrel CMSSW_10_5_0
   cd CMSSW_10_5_0/src
   cmsenv
   git cms-init
   cd $CMSSW_BASE/src 
   git clone -b HHWWgg_dev https://github.com/atishelmanch/flashgg 
   source flashgg/setup_flashgg.sh
   #+END_EXAMPLE

   If everything now looks reasonable, you can build:
   #+BEGIN_EXAMPLE
   cd $CMSSW_BASE/src
   scram b -j 4
   #+END_EXAMPLE

*** Setup Proxy 

For both the HHWWgg Dumper and Tagger, to run locally on an HHWWgg file, you first must run the following commands:

    #+BEGIN_EXAMPLE
    cmsenv
    voms-proxy-init --voms cms --valid 168:00
    #+END_EXAMPLE

after the voms command, you should get an output like:

    #+BEGIN_EXAMPLE
    Created proxy in /tmp/x509up_u95168
    #+END_EXAMPLE

to set this proxy to your X509_USER_PROXY environment variable for the example above, simply use the command:

    #+BEGIN_EXAMPLE
    . proxy.sh x509up_u95168
    #+END_EXAMPLE

where x590up_u95168 would be replaced by whatever your proxy name is. 

** HHWWgg Candidate Dumper

*** Running Locally 

The HHWWgg Candidate Dumper is run with the config file Taggers/test/HHWWggTest_cfg.py. This is useful if you'd like to run a cmsRun sequence different 
from that used in workspacestd.py. To run locally, after a scram b -j command to build everything, you need to run the command:

    #+BEGIN_EXAMPLE
    cmsRun Taggers/test/HHWWggTest_cfg.py outputFile=HHWWggtest.root metaConditions=MetaData/data/MetaConditions/Era2017_RR-31Mar2018_v1.json maxEvents=1000
    #+END_EXAMPLE

Note: The metaConditions option in this examples specifies 2017 conditions. If you'd like to run with 2016 or 2018 or some other non-standard metaconditions, this option
must be changed.

When running locally, the input files are specified in the cmssw config file (HHWWggTest_cfg.py), and by default is set to a single 250 GeV radion semileptonic decay
signal microaod with 499 events. In the config file, you can specify the variables to output with the crfTools.addCategories 
variable "variables". By default this is set to variables = Fit_Variables, which outputs minimum variables in the trees and workspaces for fggfinalfit
(CMS_hgg_mass, dZ, weight and intLumi). You can plot many more kinematic variables by changing this to variables = Reco_Variables. The specific variables to be 
plotted from these names are found in the file Taggers/python/HHWWggTagVariables.py 

Towards the end of the config file are the options zero_vtx and sands. Setting zero_vtx equal to 1 will perform the analysis dumper only considering diphotoncandidates
constructed from the highest sum pt squared vertex, found to be slightly more efficient in the case of the 250 GeV HHWWgg semileptonic signal compared to the Hgg vertex.
Setting sands equal to 1 will perform scaling and smearing corrections. 

*** Running on Condor

Running the Candidate Dumper has the advantage of allowing you to run over entire data sets and calculate weights for signal samples. Running the candidatedumper on
condor can be done with the script HHWWgg_Run_Jobs.sh. This allows you to run with the CandidateDumper or Tagger on signal or background. To run the HHWWgg dumper on signal,
you can run the command:

    #+BEGIN_EXAMPLE
    . HHWWgg_Run_Jobs.sh --labelName HHWWggTestSignal --nEvents 1000 -s
    #+END_EXAMPLE

This will create and exectue an fggrunjobs command to run the HHWWgg dumper on a maximum of 1000 events from the signal dataset specified in Taggers/test/HHWWgg_2017_Signal/HHWWgg_Signal_2017.json.
By default this json specifies the 250 GeV Radion -> HH -> WWgg -> qqlnu, semileptonic final state. If you'd like to change the dataset run on, you can edit HHWWgg_Signal_2017.json or specify another 
json file in the script. You can see Taggers/test/HHWWgg_2017_Signal/HHWWgg_Signal_example_2017.json for another example, the fully leptonic 250 GeV Radion final state. The simplest 
way to run on this dataset instead is by manually changing the two instances of qqlnu in the HHWWgg_Signal_2017.json to lnulnu. You can find the available datasets
for the current, very very preliminary HHWWgg campaign with the command: 

    #+BEGIN_EXAMPLE
    fggManageSamples.py -C HHWWgg_v1
    #+END_EXAMPLE

or

    #+BEGIN_EXAMPLE
    fggManageSamples.py -C HHWWgg_v1 list raw 
    #+END_EXAMPLE`

If you would like to run on data, you run the same HHWWgg_Run_Jobs command but with the data flag instead of the signal flag:

    #+BEGIN_EXAMPLE
    . HHWWgg_Run_Jobs.sh --labelName HHWWggTestData --nEvents 1000 -d
    #+END_EXAMPLE

By default, the json file used for specifying datasets for data is Taggers/test/HHWWgg_2017_Data_All/HHWWgg_Data_All_2017.json. At the moment, this contains 
the 2017 DoubleEG dataset. If you'd like to change this, you need to either edit this json file or specify a different json file in the HHWWgg_Run_Jobs.sh script. 

To run all all events, change --nEvents 1000 -> --nEvents all 

** HHWWgg Tagger

The HHWWgg tagger performs the same task as the dumper, but was created in order to have a compatible plugin to run with workspaceStd in order to eventually add
systematics to the analysis.

*** Running Locally 

The HHWWgg Tagger can be run locally with:

    #+BEGIN_EXAMPLE
    cmsRun Systematics/test/workspaceStd.py metaConditions=MetaData/data/MetaConditions/Era2017_RR-31Mar2018_v1.json campaign=HHWWgg_v1 dataset=ggF_X250_WWgg_qqlnugg doHHWWggTag=True HHWWggTagsOnly=True maxEvents=1000 doSystematics=False dumpWorkspace=False dumpTrees=True doBJetRegression=False
    #+END_EXAMPLE

If this worked properly, you should get an output file called: output_numEvent1000.root.

For the moment, this has not been configured to properly work with systematics, so doSystematics is set to False. This does however include shower shape corrections,
resulting in improved MVA scores compared to the HHWWgg dumper. The first customization location for this tagger is Systematics/python/HHWWggCustomize.py. 
In this you can specify variables to save, and the number of categories to save HHWWggTag objects in. The selections are located in 
Taggers/plugins/HHWWggTagProducer.cc. For the moment, a tag object "tag_obj" (naming inspired by HH->bbgg) is created if an event has a diphoton, exactly one good lepton, corresponding
to the leptonically decaying W boson, and at least two 'good' jets, corresponding to the hadronically decaying W boson. For these objects, 'good' is defined by the selections specified in 
Taggers/python/flashggHHWWggTag_cfi.py. By default this tag object is saved to category 0 (tag_obj.setCategoryNumber( catnum )). Too add another category, the number of categories
specified in Systematics/python/HHWWggCustomize.py should be changed like so: self.tagList = [ ["HHWWggTag",1] ] -> self.tagList = [ ["HHWWggTag",2] ]. Then, when saving a tag object
of the second category, you would do so in Taggers/plugins/HHWWggTagProducer.cc with tag_obj.setCategoryNumber( 1 ) rather than tag_obj.setCategoryNumber( 0 ). 

*** Running on Condor 

To run the tagger on condor, the same instructions as running the dumper with condor are followed but with the addition of the "-w" flag, like so: 

    #+BEGIN_EXAMPLE
    . HHWWgg_Run_Jobs.sh --labelName HHWWggTaggerTest --nEvents 1000 -d
    #+END_EXAMPLE

By default, this will run the tagger
on the 250 GeV Radion, semileptonic final state dataset. To change this, one needs to edit the json file used. 
